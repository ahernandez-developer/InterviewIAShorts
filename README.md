# AI Shorts Generator ğŸ¬ğŸ¤–

> Generador automÃ¡tico de **YouTube Shorts** a partir de videos largos usando Whisper, OpenAI GPT y OpenCV/FFmpeg.  
Convierte entrevistas o podcasts en clips atractivos en formato vertical listos para subir a TikTok, Reels y Shorts.

---

## ğŸš€ CaracterÃ­sticas

- ğŸ“¥ Descarga de videos desde YouTube u otras fuentes (`yt-dlp`).
- ğŸ“ TranscripciÃ³n automÃ¡tica con **Whisper** (soporte multi-idioma).
- âœ‚ï¸ SelecciÃ³n inteligente de highlights con **GPT-4**.
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ DetecciÃ³n de speakers y segmentaciÃ³n por turnos de voz.
- ğŸ¥ Recorte automÃ¡tico a formato **9:16 vertical**, centrando en rostros o Ã¡reas relevantes.
- ğŸ“‚ Genera un **manifest.json** por corrida con metadatos (timestamps, prompts, scores, modelos usados).
- ğŸ³ Compatible con Docker para despliegue en cualquier entorno.

---

## ğŸ“¦ Requisitos

- **Python 3.8+**
- **FFmpeg** instalado y accesible desde la terminal (`ffmpeg -version`)
- **OpenCV** con soporte de modelos Haar/SSD
- **Cuenta de OpenAI** y API Key activa

---

## âš™ï¸ InstalaciÃ³n

```bash
# 1. Clonar el repositorio
git clone https://github.com/ahernandez-developer/InterviewIAShorts.git
cd InterviewIAShorts

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate   # en Linux/Mac
venv\Scripts\activate    # en Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Configurar variables de entorno
cp .env.example .env
# Editar .env y colocar tu API key de OpenAI
```

---

## ğŸ”‘ ConfiguraciÃ³n

Archivo `.env`:

```ini
OPENAI_API_KEY=tu_api_key_aqui
```

Ejemplo de `.env.example` ya incluido en el repo.

---

## â–¶ï¸ Uso

Ejecutar el pipeline principal desde la raÃ­z del proyecto:

```bash
python main.py --url "https://youtube.com/watch?v=XXXX" --max-clips 5 --outdir ./outputs
```

### ParÃ¡metros disponibles

| ParÃ¡metro       | DescripciÃ³n |
|-----------------|-------------|
| `--url`         | URL del video de YouTube |
| `--max-clips`   | NÃºmero mÃ¡ximo de clips a generar |
| `--outdir`      | Carpeta de salida (default: `./outputs`) |
| `--model-size`  | TamaÃ±o del modelo Whisper (`tiny`, `base`, `small`, `medium`, `large`) |
| `--language`    | Forzar idioma de transcripciÃ³n (`es`, `en`, etc.) |

---

## ğŸ“‚ Estructura de salida

Cada corrida genera una carpeta con:

```
outputs/
â””â”€â”€ <video_id>/
    â”œâ”€â”€ clips/
    â”‚   â”œâ”€â”€ clip_01.mp4
    â”‚   â”œâ”€â”€ clip_02.mp4
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ manifest.json
    â”œâ”€â”€ transcription.txt
    â””â”€â”€ highlights.json
```

### Ejemplo `manifest.json`

```json
{
  "video_id": "abcd1234",
  "source_url": "https://youtube.com/watch?v=abcd1234",
  "created_at": "2025-08-17T12:00:00Z",
  "model": "gpt-4",
  "whisper_model": "medium",
  "clips": [
    {
      "file": "clip_01.mp4",
      "start": "00:01:23",
      "end": "00:02:45",
      "score": 0.91,
      "speaker": "Speaker 1",
      "highlight_text": "ExplicaciÃ³n clave del invitado..."
    }
  ]
}
```

---

## ğŸ³ Uso con Docker

```bash
# Construir imagen
docker build -t ai-shorts .

# Ejecutar pipeline
docker run --rm -it \
    -v $(pwd)/outputs:/app/outputs \
    -e OPENAI_API_KEY=$OPENAI_API_KEY \
    ai-shorts --url "https://youtube.com/watch?v=XXXX"
```

---

## ğŸ”§ Troubleshooting

- **`ffmpeg: command not found`** â†’ Instala FFmpeg:  
  - Ubuntu: `sudo apt install ffmpeg`  
  - Mac: `brew install ffmpeg`  
  - Windows: [descargar binarios](https://ffmpeg.org/download.html)

- **CUDA no disponible** â†’ Whisper correrÃ¡ en CPU (mÃ¡s lento).

- **API Key invÃ¡lida** â†’ Verifica tu `.env` y que la cuenta de OpenAI tenga crÃ©ditos.

---

## ğŸ“Š Roadmap

- [ ] Soporte a `faster-whisper` para transcripciones mÃ¡s rÃ¡pidas.
- [ ] GeneraciÃ³n de subtÃ­tulos (`.srt`) y *burn-in* opcional.
- [ ] UI con Gradio para uso no tÃ©cnico.
- [ ] Auto-generaciÃ³n de thumbnails y hashtags.

---

## ğŸ¤ Contribuciones

Â¡Se aceptan PRs! ğŸ™Œ  
Si quieres colaborar, abre un *issue* o crea un *pull request*.

---

## ğŸ“œ Licencia

[MIT](./LICENSE) Â© 2025
